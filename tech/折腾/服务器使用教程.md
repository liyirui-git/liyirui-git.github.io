# 实验室服务器的使用
主要是记录一个新手在使用实验室的服务器的过程中用到的那些知识和踩过的那些坑。
## 1 连接
### 1.1 Windows系统下的连接
需要下载 XShell 或者 PuTTY

服务器地址

> buaadml.info

端口号为22

### 1.2 Unix系列系统下的连接（MacOS、Linux）
直接在Terminal中输入
> ssh [your-name]@buaadml.info

然后按照提示输入密码即可登陆。此时登陆的是名为Gaia的总服务器。
Gaia上有八块Tesla M10显卡。

sshpass 命令

可以通过在一个shell脚本中的sshpass命令来连接对应的服务器。

> sshpass -p [your password] ssh [your username]@example.com

### 1.3 如何使用其他的显卡资源
此外如果想要使用其他显卡服务器上的显卡，可以输入域名登陆对应的服务器：
> Anna:      anna.buaadml.info
> Betty:     betty.buaadml.info
> Danny:   danny.buaadml.info
> Ella:       ella.buaadml.info

用户名密码与总服务器相同。

## 2 有关Linux系统
### 2.1 sh和bash和fish

### 2.2 查看计算资源
查看当前机器CPU和内存占用情况的命令是：
```
$ UTOP
```
查看当前机器上挂载的GPU的占用情况的命令是：
```
$ nvidia-smi
```
除此之外，也可以去到实验室的网站上：gpu.buaadml.info 上查看实时的GPU占用情况

### 2.3 程序后台运行

#### Screen基础

可以通过创建一个屏幕来实现后台运行，新建一个屏幕的命令是：
```
$ screen -S [screen-name] 
```
查看当前所有屏幕的列表的命令是：
```
$ screen -ls
```
进入某一个屏幕的命令是：
```
$ screen -r [screen-name]
```
kill一个屏幕的命令是在该屏幕中输入：
```
$ exit
```
#### Screen退出当前窗口但不杀死

ctrl + a + d 这一操作也叫detached。

#### Screen杀死会话窗口

如果想关掉一个多余的窗口，有3种方法：

kill -9 threadnum 例如在上面的2637，kill -9 2637 即可杀死线程，当然就杀死了窗口

使用Ctrl a +k 杀死当前窗口和窗口中运行的程序

使用Ctrl a 然后输入quit命令退出Screen会话。需要注意的是，这样退出会杀死所有窗口并退出其中运行的所有程序

#### Screen清除死去的窗口

当窗口被杀死后，再用screen -ls 可以看到该窗口后面的(???dead)字样，说明窗口死了，但是仍在占用空间。这时需要清除窗口

$ screen -wipe #自动清除死去的窗口

这样的窗明几净了~



### 2.4 从Linux传输文件到Linux服务器

在linux下一般用scp这个命令来通过ssh传输文件。

1、从服务器上下载文件
scp username@servername:/path/filename /var/www/local_dir（本地目录）

例如scp root@192.168.0.101:/var/www/test.txt 把192.168.0.101上的/var/www/test.txt 的文件下载到/var/www/local_dir（本地目录）

2、上传本地文件到服务器
scp /path/filename username@servername:/path

例如scp /var/www/test.php root@192.168.0.101:/var/www/ 把本机/var/www/目录下的test.php文件上传到192.168.0.101这台服务器上的/var/www/目录中

3、从服务器下载整个目录
scp -r username@servername:/var/www/remote_dir/（远程目录） /var/www/local_dir（本地目录）

例如:scp -r root@192.168.0.101:/var/www/test /var/www/

4、上传目录到服务器
scp -r local_dir username@servername:remote_dir
例如：scp -r test root@192.168.0.101:/var/www/ 把当前目录下的test目录上传到服务器的/var/www/ 目录

### 2.5 在Linux系统下完成下载任务

使用wget命令加上下载链接。比如要去清华anaconda镜像下下载安装包，可以使用命令：

```
$ wget  https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2019.10-Linux-x86_64.sh
```



## 3 有关 Anaconda 环境

### 3.1 下载Anaconda以及环境的搭建
主要是要注意怎么把conda命令加入到Ubuntu系统变量中
### 3.2 Anaconda镜像配置

```
$ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
$ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
$ conda config --set show_channel_urls yes
```

### 3.3 创建虚拟环境
假设当前需要创建一个 tensorflow-gpu 1.0 的环境，可以按照如下的步骤操作：
```
$ conda create -n tf1-gpu python=3.6
```
注意，tensorflow 1.x版本仅支持到python3.6
输入这一条命令以后，anaconda就会自动的配置一个python3.6版本的基础环境。之后需要进入到tf1-gpu中，去配置相应的其他环境：
```
$ conda activate tf1-gpu
```
然后就在新的环境下，配置tensorflow的环境依赖。
```
$ conda install tensorflow-gpu=1.0
```
至此一个虚拟环境就创建出来了，后面就可以在这个新的环境中愉快地玩耍了。

不过除此之外，还有一些其他常用的指令
```
conda remove -n [env-name] --all  //删除某一个环境
conda env list  //查看所创建的环境列表
```

### 3.4 导出环境配置/导入环境配置

环境配置导出

```
conda env export > environment.yaml 
```

环境配置导入

```
conda env create -f environment.yaml
```



## 4 有关TensorFLow

Tensorflow中，首先要安装tensorflow-gpu版本才能将GPU利用起来。

例如，在OpenKE中，遇到一个问题是，之前在Gaia上可以成功运行起来的，到了Betty上却无法运行。

在查看源代码是发现，程序第一行代码如下：
```
os.environ['CUDA_VISIBLE_DEVICES']='7'
```
这一行代码中7的意思是所选择的GPU号，这也就解释了为什么我可以在Gaia上运行起来（因为Gaia刚好有8块GPU）而子在Betty（只有两块）上运行不起来。改为：
```
os.environ['CUDA_VISIBLE_DEVICES']='0'
```
则可以成功运行了。
这也启发了如何指定一个训练的GPU，但是如何使用多块GPU呢？

可以在Terminal的命令中直接指定GPU，比如

```
CUDA_VISIBLE_DEVICES=1 python my_script.py
```

## 5 Pycharm 远程

可以参考下面的教程

 https://zhuanlan.zhihu.com/p/38330654 



## 6 GPU的选择

### 6.1 在终端执行程序时指定GPU  

```
CUDA_VISIBLE_DEVICES=1   python  your_file.py
```

这样在跑你的网络之前，告诉程序只能看到1号GPU，其他的GPU它不可见

可用的形式如下：

CUDA_VISIBLE_DEVICES=1           Only device 1 will be seen
CUDA_VISIBLE_DEVICES=0,1         Devices 0 and 1 will be visible
CUDA_VISIBLE_DEVICES="0,1"       Same as above, quotation marks are optional
CUDA_VISIBLE_DEVICES=0,2,3       Devices 0, 2, 3 will be visible; device 1 is masked
CUDA_VISIBLE_DEVICES=""          No GPU will be visible

### 6.2 在Python代码中指定GPU

```
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
```

### 6.3 在TensorFlow中

设置定量的GPU使用量：

```
config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.9 # 占用GPU90%的显存
session = tf.Session(config=config)
```

设置最小的GPU使用量：

```
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
session = tf.Session(config=config)

```

